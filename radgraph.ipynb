{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \\\n",
        "  torch>=2.1.0 \\\n",
        "  transformers>=4.39.0 \\\n",
        "  appdirs \\\n",
        "  jsonpickle \\\n",
        "  filelock \\\n",
        "  h5py \\\n",
        "  nltk \\\n",
        "  dotmap \\\n",
        "  pytest\n"
      ],
      "metadata": {
        "id": "BMfuFiN-oDUP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install radgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9zp2eXqyon-L",
        "outputId": "c69f44a4-e680-4e6c-b1ea-7d266110946d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting radgraph\n",
            "  Downloading radgraph-0.1.18.tar.gz (587 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/588.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/588.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.0/588.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from radgraph) (2.9.0+cpu)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.12/dist-packages (from radgraph) (4.57.3)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from radgraph) (1.4.4)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.12/dist-packages (from radgraph) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from radgraph) (3.20.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from radgraph) (3.15.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from radgraph) (3.9.1)\n",
            "Requirement already satisfied: dotmap in /usr/local/lib/python3.12/dist-packages (from radgraph) (1.3.30)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from radgraph) (8.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->radgraph) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->radgraph) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->radgraph) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->radgraph) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->radgraph) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->radgraph) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->radgraph) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->radgraph) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->radgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->radgraph) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->radgraph) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->radgraph) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->radgraph) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->radgraph) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->radgraph) (4.67.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->radgraph) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->radgraph) (1.5.2)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->radgraph) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->radgraph) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->radgraph) (2.19.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.39.0->radgraph) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->radgraph) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->radgraph) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.39.0->radgraph) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.39.0->radgraph) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.39.0->radgraph) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.39.0->radgraph) (2025.11.12)\n",
            "Building wheels for collected packages: radgraph\n",
            "  Building wheel for radgraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for radgraph: filename=radgraph-0.1.18-py3-none-any.whl size=812635 sha256=2e293d289b3d26e970c220839ec84b4615fbde84abcdf9fbaca061c6f174eb6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/3c/fb/214f5d5cdab2a0f9f0904fd81d7fd1134404100b4444554df8\n",
            "Successfully built radgraph\n",
            "Installing collected packages: radgraph\n",
            "Successfully installed radgraph-0.1.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from radgraph import get_radgraph_processed_annotations, RadGraph"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3-kL8RjqrFIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f19e2f7-09b0-4047-9f59-a9d0c82af724"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import re\n"
      ],
      "metadata": {
        "id": "Ttx8RgIVcEc3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(x):\n",
        "    if not x:\n",
        "        return \"\"\n",
        "    if isinstance(x, list):\n",
        "        return \", \".join(x)\n",
        "    return str(x)\n",
        "\n",
        "\n",
        "def annotation_to_sentence(annotation):\n",
        "    obs = clean_text(annotation.get(\"observation\"))\n",
        "    loc = clean_text(annotation.get(\"located_at\"))\n",
        "    sug = clean_text(annotation.get(\"suggestive_of\"))\n",
        "    tag = annotation.get(\"tags\", [\"\"])[0]\n",
        "\n",
        "    # Normalize tag\n",
        "    tag = re.sub(\"_\", \" \", tag)\n",
        "\n",
        "    parts = []\n",
        "\n",
        "    # Handle ABSENT case first\n",
        "    if tag == \"definitely absent\":\n",
        "        if obs:\n",
        "            sentence = f\"No {obs}\"\n",
        "            if loc:\n",
        "                sentence += f\" in the {loc}\"\n",
        "            sentence += \".\"\n",
        "            return sentence\n",
        "\n",
        "    # PRESENT (or unknown) case\n",
        "    if obs:\n",
        "        parts.append(obs.capitalize())\n",
        "\n",
        "    if loc:\n",
        "        parts.append(f\"in the {loc}\")\n",
        "\n",
        "    if sug:\n",
        "        parts.append(f\"suggestive of {sug}\")\n",
        "\n",
        "    sentence = \" \".join(parts).strip()\n",
        "\n",
        "    if sentence and not sentence.endswith(\".\"):\n",
        "        sentence += \".\"\n",
        "\n",
        "    return sentence\n"
      ],
      "metadata": {
        "id": "vRgsuzOiZoN3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AYXAqxZ35YuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv(\"/content/output.csv\")\n",
        "\n",
        "clean = (\n",
        "    df.iloc[33333:33734, 0]\n",
        "      .astype(str)\n",
        "      .str.replace(r'^FINDINGS:\\s*', '', regex=True)\n",
        "      .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "      .str.strip()\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "concepts = df.iloc[33333:33734, 1].reset_index(drop=True)\n",
        "\n",
        "eval_df = pd.DataFrame({\"report\": clean, \"concepts\": concepts})\n",
        "model_type = \"modern-radgraph-xl\"\n",
        "radgraph = RadGraph(model_type=model_type)\n",
        "reports = eval_df[\"report\"].astype(str).tolist()\n",
        "\n",
        "pred_concepts = []\n",
        "\n",
        "for report in reports:\n",
        "    annotations = radgraph([report])  # one report batch\n",
        "    processed = get_radgraph_processed_annotations(annotations)  # dict with \"processed_annotations\"\n",
        "\n",
        "    sents = []\n",
        "    for ann in processed[\"processed_annotations\"]:\n",
        "        s = annotation_to_sentence(ann)\n",
        "        if s:\n",
        "            sents.append(s)\n",
        "\n",
        "    pred_concepts.append(list(dict.fromkeys(sents)))\n",
        "\n",
        "reports = eval_df[\"report\"].astype(str).tolist()\n",
        "\n",
        "gt_concepts = [\n",
        "    ast.literal_eval(x) if pd.notna(x) else []\n",
        "    for x in eval_df[\"concepts\"].tolist()\n",
        "]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRhLeEmBpXXG",
        "outputId": "c6a125d5-eb63-4748-9861-d635fe4108d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def canonicalize_concept(s: str) -> str:\n",
        "    s = str(s).strip().lower()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    s = s.rstrip(\".\")\n",
        "    s = s.replace(\"top - normal\", \"normal\")\n",
        "    s = s.replace(\"within normal limits\", \"normal\")\n",
        "    s = s.replace(\"unremarkable\", \"normal\")\n",
        "\n",
        "    # reorder templates to match GT phrase style\n",
        "    # \"no effusion in the pleural\" -> \"no pleural effusion\"\n",
        "    m = re.match(r\"^no (.+?) in the (.+)$\", s)\n",
        "    if m:\n",
        "        obs, loc = m.group(1), m.group(2)\n",
        "        s = f\"no {loc} {obs}\"\n",
        "\n",
        "    # \"calcified in the aorta\" -> \"calcified aorta\"\n",
        "    m = re.match(r\"^(.+?) in the (.+)$\", s)\n",
        "    if m:\n",
        "        obs, loc = m.group(1), m.group(2)\n",
        "        s = f\"{obs} {loc}\"\n",
        "\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "\n",
        "    # drop single-word leftovers (these usually come from missing location)\n",
        "    if len(s.split()) == 1:\n",
        "        return \"\"\n",
        "\n",
        "    return s\n",
        "\n",
        "gt_norm   = [[canonicalize_concept(x) for x in xs] for xs in gt_concepts]\n",
        "pred_norm = [[canonicalize_concept(x) for x in xs] for xs in pred_concepts]\n",
        "\n",
        "# remove blanks\n",
        "gt_norm   = [[x for x in xs if x] for xs in gt_norm]\n",
        "pred_norm = [[x for x in xs if x] for xs in pred_norm]\n",
        "\n"
      ],
      "metadata": {
        "id": "AvjtIHw9ri05"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in (34,43,25,38,22,79,223,185,113,83,67):\n",
        "  print(reports[i])\n",
        "  print(i,\" :\")\n",
        "  print(gt_norm[i],'\\n',pred_norm[i],'\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxaaJORV0xXc",
        "outputId": "7c226e6f-754a-4e36-9267-b2ab5304ed6c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lungs are hyperexpanded, but clear. There is no pleural abnormality. The cardiac and mediastinal silhouettes are unremarkable. Multiple rib deformities with callus formation is again seen.\n",
            "34  :\n",
            "['hyperexpanded lungs', 'clear lungs', 'no pleural abnormality', 'normal cardiac silhouette', 'normal mediastinal silhouette', 'rib deformities with callus formation'] \n",
            " ['hyperexpanded lungs', 'clear lungs', 'no pleural abnormality', 'normal cardiac silhouettes, mediastinal silhouettes', 'multiple deformities rib', 'callus formation'] \n",
            "\n",
            "The patient is status post median sternotomy and CABG. The heart size is normal. The mediastinal and hilar contours are unremarkable. The pulmonary vasculature is normal in the lungs are clear. No focal consolidation, pleural effusion or pneumothorax is visualized. There are no acute osseous abnormalities. Partially imaged is cervical spinal fusion hardware.\n",
            "43  :\n",
            "['status post median sternotomy and cabg', 'normal heart size', 'normal mediastinal and hilar contours', 'normal pulmonary vasculature', 'no focal consolidation', 'no pleural effusion', 'no pneumothorax', 'no acute osseous abnormalities', 'partially imaged cervical spinal fusion hardware'] \n",
            " ['normal heart size', 'normal mediastinal contours, hilar contours', 'normal pulmonary vasculature', 'no focal consolidation', 'no pleural effusion', 'no pneumothorax', 'no osseous acute abnormalities', 'fusion hardware spinal'] \n",
            "\n",
            "Two views were obtained of the chest. The lungs are relatively well expanded and clear. There is no pleural effusion or pneumothorax. The heart is normal in size with normal cardiomediastinal contours.\n",
            "25  :\n",
            "['two views', 'relatively well expanded lungs', 'clear lungs', 'no pleural effusion', 'normal heart size', 'normal cardiomediastinal contours'] \n",
            " ['well expanded lungs', 'clear lungs', 'no pleural effusion', 'no pneumothorax', 'normal heart size'] \n",
            "\n",
            "Two frontal views of the chest demonstrate an esophageal tube which courses below the diaphragm, into the stomach and out of view. The lungs demonstrate no evidence of focal opacification concerning for pneumonia or aspiration. There is no pleural effusion or pulmonary edema. No pneumothorax is present.\n",
            "38  :\n",
            "['esophageal tube', 'no focal opacification', 'no pneumonia', 'no aspiration', 'no pleural effusion', 'no pulmonary edema', 'no pneumothorax'] \n",
            " ['esophageal tube out of view stomach', 'no lungs focal opacification', 'no pneumonia', 'no aspiration', 'no pleural effusion', 'no pulmonary edema', 'no pneumothorax'] \n",
            "\n",
            "Heart size is upper limits of normal and unchanged. The mediastinal and hilar contours are normal. The pulmonary vasculature is normal. Lungs are clear. Focal left pleural thickening is long-standing and unchanged. No pleural effusion or pneumothorax is seen. There are no acute osseous abnormalities.\n",
            "22  :\n",
            "['normal heart size', 'normal mediastinal and hilar contours', 'normal pulmonary vasculature', 'clear lungs', 'long-standing left pleural thickening', 'no pleural effusion', 'no pneumothorax', 'no acute osseous abnormalities'] \n",
            " ['upper limits of normal', 'normal mediastinal contours, hilar contours', 'clear lungs', 'focal thickening long - standing unchanged left pleural', 'no pleural effusion', 'no pneumothorax', 'no osseous acute abnormalities'] \n",
            "\n",
            "PA and lateral views of the chest are compared to previous exam from ___. The lungs are hyperinflated but are clear of consolidation. The cardiomediastinal silhouette is within normal limits. Osseous and soft tissue structures are unremarkable.\n",
            "79  :\n",
            "['pa and lateral views compared to previous exam', 'clear lungs', 'normal cardiomediastinal silhouette', 'normal osseous and soft tissue structures'] \n",
            " ['hyperinflated lungs', 'no lungs consolidation', 'normal cardiomediastinal silhouette', 'normal osseous structures, soft tissue structures'] \n",
            "\n",
            "Frontal and lateral radiographs of the chest demonstrate persistent though improved fluid in the minor fissure on the right, and small right sided pleural effusion with adjacent atelectasis. There is a stable appearing moderate-to-large left sided pleural effusion with adjacent atelectasis on the left. There is mild asymmetric pulmonary edema on the right. The cardiomediastinal and hilar contours are unchanged. There is no pneumothorax.\n",
            "223  :\n",
            "['persistent fluid in minor fissure on right', 'small right sided pleural effusion with adjacent atelectasis', 'stable appearing moderate-to-large left sided pleural effusion with adjacent atelectasis', 'mild asymmetric pulmonary edema on right', 'no pneumothorax'] \n",
            " ['improved fluid', 'small effusion right sided pleural', 'stable moderate - to - large effusion left sided pleural', 'atelectasis left', 'mild asymmetric edema pulmonary right', 'unchanged cardiomediastinal contours, hilar contours', 'no pneumothorax'] \n",
            "\n",
            "Heart size is normal. The mediastinal and hilar contours are normal. The pulmonary vasculature is normal. Lungs are clear. No pleural effusion or pneumothorax is seen. There are no acute osseous abnormalities. Bilateral breast implants are again noted.\n",
            "185  :\n",
            "['normal heart size', 'normal mediastinal and hilar contours', 'normal pulmonary vasculature', 'clear lungs', 'no pleural effusion', 'no pneumothorax', 'no acute osseous abnormalities', 'bilateral breast implants'] \n",
            " ['normal heart size', 'normal mediastinal contours, hilar contours', 'normal pulmonary vasculature', 'clear lungs', 'no pleural effusion', 'no pneumothorax', 'no osseous acute abnormalities', 'implants bilateral breast'] \n",
            "\n",
            "Lungs are clear. Cardiac silhouette is normal. No pleural effusion, pneumothorax or pulmonary edema. No displaced fracture seen.\n",
            "113  :\n",
            "['clear lungs', 'normal cardiac silhouette', 'no pleural effusion', 'no pneumothorax', 'no pulmonary edema', 'no displaced fracture'] \n",
            " ['clear lungs', 'normal cardiac silhouette', 'no pleural effusion', 'no pneumothorax', 'no pulmonary edema', 'no displaced fracture'] \n",
            "\n",
            "There has been no significant interval change. The appearance of the left hemidiaphragm is stable. No focal consolidation is seen. There is no large pleural effusion or pneumothorax. The cardiac and mediastinal silhouettes are stable. The patient is rotated somewhat to the left. Multiple surgical clips are seen overlying the upper abdomen. .\n",
            "83  :\n",
            "['no significant interval change', 'stable left hemidiaphragm', 'no focal consolidation', 'no large pleural effusion', 'no pneumothorax', 'stable cardiac and mediastinal silhouettes', 'patient rotated to the left', 'surgical clips overlying upper abdomen'] \n",
            " ['stable left hemidiaphragm', 'no focal consolidation', 'no pleural large effusion', 'no pneumothorax', 'stable cardiac silhouettes, mediastinal silhouettes', 'multiple surgical clips upper abdomen'] \n",
            "\n",
            "Frontal and lateral views of the chest are compared to previous exam from ___. The lungs are clear. Cardiomediastinal silhouette is stable. Osseous and soft tissue structures are unremarkable. Surgical clips in the upper abdomen suggest prior cholecystectomy.\n",
            "67  :\n",
            "['comparison to previous exam', 'clear lungs', 'stable cardiomediastinal silhouette', 'normal osseous and soft tissue structures', 'surgical clips in upper abdomen'] \n",
            " ['clear lungs', 'stable cardiomediastinal silhouette', 'normal osseous structures, soft tissue structures', 'surgical clips upper abdomen suggestive of clips suggestive of cholecystectomy'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity1(a: str, b: str) -> float:\n",
        "    a_tokens = set(a.lower().split())\n",
        "    b_tokens = set(b.lower().split())\n",
        "\n",
        "    if not a_tokens and not b_tokens:\n",
        "        return 1.0\n",
        "    if not a_tokens or not b_tokens:\n",
        "        return 0.0\n",
        "\n",
        "    intersection = a_tokens & b_tokens\n",
        "    union = a_tokens | b_tokens\n",
        "\n",
        "    return len(intersection) / len(union)\n"
      ],
      "metadata": {
        "id": "-3cZG6BV8wxO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity2(a: str, b: str) -> float:\n",
        "    a_tokens = set(a.lower().split())\n",
        "    b_tokens = set(b.lower().split())\n",
        "\n",
        "    if not a_tokens and not b_tokens:\n",
        "        return 1.0\n",
        "    if not a_tokens or not b_tokens:\n",
        "        return 0.0\n",
        "\n",
        "    intersection = a_tokens & b_tokens\n",
        "    union = a_tokens | b_tokens\n",
        "\n",
        "    return (2*len(intersection)) / (len(a_tokens)+len(b_tokens))\n"
      ],
      "metadata": {
        "id": "VfGJ30l_GEjw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fuzzy_counts_one(gt_list, pred_list, threshold):\n",
        "    gt = [g.strip().lower() for g in gt_list if g.strip()]\n",
        "    pr = [p.strip().lower() for p in pred_list if p.strip()]\n",
        "\n",
        "    used_gt = set()\n",
        "    TP = 0\n",
        "\n",
        "    for p in pr:\n",
        "        best_j = None\n",
        "        best_score = 0.0\n",
        "\n",
        "        for j, g in enumerate(gt):\n",
        "            if j in used_gt:\n",
        "                continue\n",
        "\n",
        "            score = similarity2(p, g)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_j = j\n",
        "\n",
        "        if best_j is not None and best_score >= threshold:\n",
        "            TP += 1\n",
        "            used_gt.add(best_j)\n",
        "\n",
        "    FP = len(pr) - TP\n",
        "    FN = len(gt) - TP\n",
        "\n",
        "    return TP, FP, FN\n"
      ],
      "metadata": {
        "id": "7kBFWmYR83Iv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fuzzy_prf(gt_norm, pred_norm, threshold):\n",
        "    TP = FP = FN = 0\n",
        "\n",
        "    for gt, pr in zip(gt_norm, pred_norm):\n",
        "        t, f, n = fuzzy_counts_one(gt, pr, threshold)\n",
        "        TP += t\n",
        "        FP += f\n",
        "        FN += n\n",
        "\n",
        "    precision = TP / (TP + FP) if TP + FP else 0\n",
        "    recall    = TP / (TP + FN) if TP + FN else 0\n",
        "    f1        = (2 * precision * recall / (precision + recall)) if precision + recall else 0\n",
        "\n",
        "    return precision, recall, f1, (TP, FP, FN)\n"
      ],
      "metadata": {
        "id": "Fpisl6ol87X6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for th in [0.7,0.75, 0.8, 0.85,0.9]:\n",
        "    P, R, F1, counts = fuzzy_prf(gt_norm, pred_norm, threshold=th)\n",
        "    print(th, P, R, F1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01p8BmWWADVm",
        "outputId": "e5609ac4-e344-43bd-de64-8dd42b1a4ddc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7 0.6802120141342756 0.6787729196050776 0.6794917049064595\n",
            "0.75 0.6646643109540636 0.6632581100141044 0.6639604659371692\n",
            "0.8 0.6353356890459364 0.6339915373765868 0.6346629015178257\n",
            "0.85 0.5565371024734982 0.5553596614950634 0.5559477585598306\n",
            "0.9 0.49469964664310956 0.4936530324400564 0.494175785386516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "no fuzzy"
      ],
      "metadata": {
        "id": "kkSZRvud82jJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TP = FP = FN = 0\n",
        "\n",
        "for g_list, p_list in zip(gt_norm, pred_norm):\n",
        "    g = set(g_list)\n",
        "    p = set(p_list)\n",
        "\n",
        "    TP += len(g & p)\n",
        "    FP += len(p - g)\n",
        "    FN += len(g - p)\n",
        "\n",
        "precision = TP / (TP + FP) if (TP + FP) else 0\n",
        "recall    = TP / (TP + FN) if (TP + FN) else 0\n",
        "f1        = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0\n",
        "\n",
        "print(\"TP FP FN:\", TP, FP, FN)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nSyhtCbriCv",
        "outputId": "f0b5f47d-d247-4b7b-dded-c2d1e42b8ef0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TP FP FN: 1125 1705 1711\n",
            "Precision: 0.39752650176678445\n",
            "Recall: 0.3966854724964739\n",
            "F1: 0.3971055418284504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset_correct = 0\n",
        "for g_list, p_list in zip(gt_norm, pred_norm):\n",
        "    if set(g_list) == set(p_list):\n",
        "        subset_correct += 1\n",
        "\n",
        "subset_accuracy = subset_correct / len(gt_norm) if len(gt_norm) else 0\n",
        "print(\"Subset accuracy:\", subset_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThjBQ_RnqXU0",
        "outputId": "97f561f2-15da-4900-dedb-ea1f908115e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset accuracy: 0.00997506234413965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_set = sorted(set(x for xs in gt_norm for x in xs) | set(x for xs in pred_norm for x in xs))\n",
        "L = len(label_set)\n",
        "N = len(gt_norm)\n",
        "\n",
        "mismatches = 0\n",
        "for g_list, p_list in zip(gt_norm, pred_norm):\n",
        "    g = set(g_list)\n",
        "    p = set(p_list)\n",
        "    for lbl in label_set:\n",
        "        mismatches += int((lbl in g) ^ (lbl in p))\n",
        "\n",
        "hamming_loss = mismatches / (N * L) if (N * L) else 0\n",
        "print(\"Hamming loss:\", hamming_loss)\n",
        "print(\"N (reports):\", N, \"L (labels):\", L)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OoqG6yXw1RM",
        "outputId": "0dedbfc3-6688-4d97-cd37-870cf387e738"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hamming loss: 0.004052665671691371\n",
            "N (reports): 401 L (labels): 2102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gv9UC2agw3EF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}